{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P02_Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap for Categorical features\n",
    "\n",
    "* x3 is nominal categorical feature (needs OneHotEncoder transformer) and custom function edit is needed\n",
    "* x7 column: the % sign should be cleaned from strings and I need to change the dtype and introduce it as numeric feature.\n",
    "* x19 column: the % sign should be cleaned from strings and I need to change the dtype and introduce it as numeric feature.\n",
    "* x24 column: is nominal category and needs to be transformed using One Hot Encoding\n",
    "* x31 column: is nominal category and needs to be transformed using One Hot Encoding\n",
    "* x33 column: is nominal category and needs to be transformed using One Hot Encoding\n",
    "* x39 should be droped the column \n",
    "* x60 is nominal and OneHotEncoder should be used to transfer this column\n",
    "* x65 is nominal and OneHotEncoder should be used to transfer this column\n",
    "* x77 is nominal and OneHotEncoder should be used to transfer this column\n",
    "* x93 is nominal and OneHotEncoder should be used to transfer this column\n",
    "* X99 should be droped - it has just one category. \n",
    "* The x24, x33, and x77 columns NaN values needs to be replaced by their mode.\n",
    "\n",
    "\n",
    "# Recap for Numerical features\n",
    "\n",
    "\n",
    "- Column 'x30', 'x44', 'x57' have more than 50% nan and should be droped\n",
    "- Three features inside the numeric df need to be transformed using One Hot Encoding. These are features with 0-1 values and should be treated like category features. These are 0-1 features and should be treated like category features. columns are x59 and x79 and x98\n",
    "- I may use Isolation Forest or LOF for outlier detection. I will check the AUC to see the differences.\n",
    "- High score numerical features are as follow:\n",
    "```['x16', 'x18', 'x28', 'x32', 'x35', 'x40', 'x47', 'x52', 'x57', 'x62', 'x68', 'x70', 'x75', 'x78', 'x81', 'x88', 'x89', 'x95', 'x96']```\n",
    "- With n_components=12, I get 0.62 AUC and as it is seen 12 principal components have 62٪ of variance. I may apply PCA if I found not using it computationally time expensive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../DataSet/\"\n",
    "file_name = \"exercise_40_train.csv\"\n",
    "df = pd.read_csv(file_path+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 101)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x91</th>\n",
       "      <th>x92</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x95</th>\n",
       "      <th>x96</th>\n",
       "      <th>x97</th>\n",
       "      <th>x98</th>\n",
       "      <th>x99</th>\n",
       "      <th>x100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.165254</td>\n",
       "      <td>18.060003</td>\n",
       "      <td>Wed</td>\n",
       "      <td>1.077380</td>\n",
       "      <td>-1.339233</td>\n",
       "      <td>-1.584341</td>\n",
       "      <td>0.0062%</td>\n",
       "      <td>0.220784</td>\n",
       "      <td>1.816481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.397427</td>\n",
       "      <td>0.909479</td>\n",
       "      <td>no</td>\n",
       "      <td>5.492487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.255579</td>\n",
       "      <td>7.627730</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>104.251338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.441471</td>\n",
       "      <td>18.416307</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1.482586</td>\n",
       "      <td>0.920817</td>\n",
       "      <td>-0.759931</td>\n",
       "      <td>0.0064%</td>\n",
       "      <td>1.192441</td>\n",
       "      <td>3.513950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656651</td>\n",
       "      <td>9.093466</td>\n",
       "      <td>no</td>\n",
       "      <td>3.346429</td>\n",
       "      <td>4.321172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.505284</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>101.230645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4.427278</td>\n",
       "      <td>19.188092</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0.145652</td>\n",
       "      <td>0.366093</td>\n",
       "      <td>0.709962</td>\n",
       "      <td>-8e-04%</td>\n",
       "      <td>0.952323</td>\n",
       "      <td>0.782974</td>\n",
       "      <td>...</td>\n",
       "      <td>2.059615</td>\n",
       "      <td>0.305170</td>\n",
       "      <td>no</td>\n",
       "      <td>4.456565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.754572</td>\n",
       "      <td>7.810979</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>109.345215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.925235</td>\n",
       "      <td>19.901257</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1.763602</td>\n",
       "      <td>-0.251926</td>\n",
       "      <td>-0.827461</td>\n",
       "      <td>-0.0057%</td>\n",
       "      <td>-0.520756</td>\n",
       "      <td>1.825586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899392</td>\n",
       "      <td>5.971782</td>\n",
       "      <td>no</td>\n",
       "      <td>4.100022</td>\n",
       "      <td>1.151085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.178325</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>103.021970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.868802</td>\n",
       "      <td>22.202473</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>3.405119</td>\n",
       "      <td>0.083162</td>\n",
       "      <td>1.381504</td>\n",
       "      <td>0.0109%</td>\n",
       "      <td>-0.732739</td>\n",
       "      <td>2.151990</td>\n",
       "      <td>...</td>\n",
       "      <td>3.003595</td>\n",
       "      <td>1.046096</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.234033</td>\n",
       "      <td>2.074927</td>\n",
       "      <td>9.987006</td>\n",
       "      <td>11.702664</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>92.925935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y        x1         x2        x3        x4        x5        x6        x7  \\\n",
       "0  0  0.165254  18.060003       Wed  1.077380 -1.339233 -1.584341   0.0062%   \n",
       "1  1  2.441471  18.416307    Friday  1.482586  0.920817 -0.759931   0.0064%   \n",
       "2  1  4.427278  19.188092  Thursday  0.145652  0.366093  0.709962   -8e-04%   \n",
       "3  0  3.925235  19.901257   Tuesday  1.763602 -0.251926 -0.827461  -0.0057%   \n",
       "4  0  2.868802  22.202473    Sunday  3.405119  0.083162  1.381504   0.0109%   \n",
       "\n",
       "         x8        x9  ...       x91       x92  x93       x94       x95  \\\n",
       "0  0.220784  1.816481  ... -0.397427  0.909479   no  5.492487       NaN   \n",
       "1  1.192441  3.513950  ...  0.656651  9.093466   no  3.346429  4.321172   \n",
       "2  0.952323  0.782974  ...  2.059615  0.305170   no  4.456565       NaN   \n",
       "3 -0.520756  1.825586  ...  0.899392  5.971782   no  4.100022  1.151085   \n",
       "4 -0.732739  2.151990  ...  3.003595  1.046096  yes  3.234033  2.074927   \n",
       "\n",
       "         x96        x97  x98  x99        x100  \n",
       "0  10.255579   7.627730    0  yes  104.251338  \n",
       "1        NaN  10.505284    1  yes  101.230645  \n",
       "2   8.754572   7.810979    0  yes  109.345215  \n",
       "3        NaN   9.178325    1  yes  103.021970  \n",
       "4   9.987006  11.702664    0  yes   92.925935  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_numeric_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b3cebaa6f7ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# https://stackoverflow.com/questions/54160370/how-to-use-sklearn-column-transformer/54160620\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnumeric_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_numeric_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m numeric_transformer = Pipeline(steps=[\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'imputer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'median'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_numeric_features' is not defined"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/54160370/how-to-use-sklearn-column-transformer/54160620\n",
    "\n",
    "numeric_features = df_numeric_features.columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = X_catg.columns\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(solver='lbfgs',\n",
    "                                                        weights=weights))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "X = X_all_features\n",
    "y = df['y']\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
